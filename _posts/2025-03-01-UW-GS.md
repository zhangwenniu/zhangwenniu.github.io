---
layout: mypost
title: UW-GS, Distractor-Aware 3D Gaussian Splatting for Enhanced Underwater Scene Reconstruction
categories: [3DGS, 水下]
---

# 论文链接

- [论文链接](https://arxiv.org/abs/2410.01517)

- [Github链接](https://github.com/WangHaoran16/UW-GS)


# 重点难点介绍

## 论文重点内容

### 1. **研究目标**

本文提出了一种针对水下场景的新型3D高斯点绘制方法（UW-GS），旨在解决传统3D高斯点绘制（3DGS）在水下环境中表现不佳的问题。水下场景的特点包括：

- **光吸收和散射**：导致颜色失真、对比度下降。

- **动态物体干扰**：如游动的鱼和漂浮物，会引入重建伪影。

- **远距离物体模糊**：由于光衰减，远距离区域的细节难以重建。

### 2. **核心贡献**

本文的主要贡献包括：

1. **新型颜色表现模型**  

   通过多层感知机（MLP）估计水下介质参数（如衰减因子、背景光等），并根据这些参数调整高斯点的颜色，从而更好地模拟水下场景的颜色变化。这一模型能够有效解决因光衰减和散射导致的颜色失真问题。

2. **基于物理的密度控制策略**  

   针对远距离物体因光衰减导致的高斯点稀疏问题，本文提出了一种新的密度控制策略。通过补偿光衰减对梯度计算的影响，使得高斯点能够在远距离区域更有效地分裂和克隆，从而提高重建质量，减少模糊伪影。

3. **二值运动掩码（BMM）**  

   为处理动态物体的干扰，本文引入了二值运动掩码。在训练过程中，通过检测和排除动态物体的影响，显著提高了重建结果的鲁棒性，避免了动态物体引入的伪影。

4. **新的损失函数**  

   结合散射介质特性、伪深度图和像素级二值运动掩码，设计了一种新的损失函数，用于优化模型参数，进一步提高重建精度。

5. **新的水下数据集（S-UW）**
  
   为了验证方法的有效性，作者收集了一个新的水下数据集，包含动态物体掩码，为后续研究提供了宝贵的资源。

### 3. **实验验证**

- **数据集**：在SeaThru-NeRF、IW和S-UW三个数据集上验证了UW-GS的有效性。

- **性能指标**：使用PSNR、SSIM和LPIPS三个指标评估重建质量。

- **结果**：UW-GS在多个场景中均优于现有的3DGS和SeaThru-NeRF方法，平均PSNR提升高达1.26dB，证明了其在水下场景重建中的优越性。



## 论文难点内容

### 1. **颜色表现模型的复杂性**

- **难点**：如何准确估计水下介质参数（如衰减因子、背景光等），并将其与高斯点的颜色表现相结合。

- **解决方案**：通过多层感知机（MLP）估计这些参数，并利用仿射变换调整高斯点的颜色。这一过程需要精确的物理模型支持，同时需要大量训练数据以确保模型的泛化能力。

### 2. **基于物理的密度控制策略**

- **难点**：在水下环境中，光的衰减会导致高斯点的梯度信息丢失，使得远距离区域的高斯点难以分裂和克隆，从而导致重建结果模糊。

- **解决方案**：通过补偿光衰减对梯度计算的影响，调整高斯点的分裂和克隆策略。这一策略需要精确估计光衰减因子，并在训练过程中动态调整密度控制策略。

### 3. **动态物体的处理**

- **难点**：水下场景中的动态物体（如游动的鱼和漂浮物）会引入重建伪影，如何在训练过程中排除这些动态物体的影响是一个挑战。

- **解决方案**：引入二值运动掩码（BMM），通过检测动态物体并将其从训练数据中排除，从而提高重建结果的鲁棒性。这一方法需要精确的动态物体检测算法，并在训练过程中动态调整掩码。

### 4. **损失函数的设计**

- **难点**：如何设计一个能够同时考虑散射介质特性、伪深度图和动态物体影响的损失函数，以优化模型参数并提高重建精度。

- **解决方案**：结合散射介质特性、伪深度图和像素级二值运动掩码，设计了一个综合损失函数。这一损失函数需要在训练过程中动态调整权重，以平衡不同因素的影响。

### 5. **浅水场景的挑战**

- **难点**：在浅水场景中，水面光线的干扰较大，导致光衰减和散射的影响更加复杂，模型的性能提升不如深水场景明显。

- **解决方案**：尽管UW-GS在浅水场景中表现良好，但作者指出，浅水场景的复杂性仍然是一个需要进一步研究的方向。未来的工作可能需要引入更多的物理模型和数据增强方法，以进一步提高模型在浅水场景中的性能。



## 总结

本文通过提出一种新型的3D高斯点绘制方法（UW-GS），解决了传统方法在水下场景中的不足。通过引入新的颜色表现模型、基于物理的密度控制策略和二值运动掩码，显著提高了水下场景重建的质量。尽管在浅水场景中仍存在挑战，但UW-GS为水下场景重建领域提供了新的思路和方法。

# 详细介绍

UW-GS: Distractor-Aware 3D Gaussian Splatting for Enhanced Underwater Scene Reconstruction

### **1. 论文信息**
- **标题**: UW-GS: Distractor-Aware 3D Gaussian Splatting for Enhanced Underwater Scene Reconstruction  
- **作者**: Haoran Wang, Nantheera Anantrasirichai, Fan Zhang, David Bull  
- **单位**: School of Computer Science, University of Bristol, Bristol, UK  
- **联系方式**: {yp22378,n.anantrasirichai,fan.zhang,dave.bull}@bristol.ac.uk  
- **代码地址**: [https://github.com/WangHaoran16/UW-GS](https://github.com/WangHaoran16/UW-GS)  
- **论文版本**: arXiv:2410.01517v2 cs.CV 23 Dec 2024

### **2. 研究背景**

水下场景重建在海洋考古、地质勘探、海洋科学等领域具有重要应用价值。然而，水下环境复杂，光的传播受到吸收和散射的影响，导致图像对比度下降、颜色失真。此外，水下场景中还存在动态物体（如游动的鱼和漂浮物），这些物体会给3D重建带来额外的挑战。传统的3D高斯点绘制（3DGS）方法在水下场景中表现不佳，主要原因是：

1. 3DGS假设场景处于透明介质中，无法有效处理水下的光衰减和散射。

2. 动态物体的存在会导致重建结果中出现伪影。

3. 远距离物体的颜色信息因光衰减而变得稀疏，导致重建结果模糊。

### **3. 研究动机**

为了解决上述问题，本文提出了一种针对水下场景的新型3D高斯点绘制方法（UW-GS），通过改进颜色表现模型、密度控制策略和动态内容处理，显著提升了水下场景重建的质量。

### **4. 方法介绍**

#### **4.1 问题定义**

3D高斯点绘制（3DGS）是一种基于点云的3D场景表示方法，通过一组高斯点（Gaussians）来表示场景。每个高斯点由中心位置（µ）、协方差矩阵（Σ）、透明度（α）和视图依赖的颜色（c）组成。在渲染时，这些高斯点被投影到2D空间，通过α混合生成最终图像颜色。

在水下环境中，由于光的吸收和散射，传统的3DGS方法无法有效表示场景。本文通过引入新的颜色表现模型、基于物理的密度控制策略和二值运动掩码（BMM），解决了这些问题。

#### **4.2 新的颜色表现模型**

传统的3DGS方法使用球谐函数（Spherical Harmonics, SH）来表示视图依赖的颜色，但这种方法假设场景处于透明介质中，无法处理水下的光衰减和散射。为了解决这一问题，本文提出了一个新的颜色表现模型，通过多层感知机（MLP）估计水介质参数，并根据这些参数调整高斯点的颜色。

具体来说，MLP以高斯点的深度（z）和视图方向（θ）为输入，估计以下参数：

- **衰减因子（TD）**：表示直接光的衰减。

- **背景光因子（TB）**：表示散射光的影响。

- **介质系数（βd, βb）**：用于调节衰减和散射的影响。

- **背景光颜色（b）**：表示无限远处的背景光颜色。

通过这些参数，可以计算出修正后的高斯点颜色（cm）：

$$ cm = TD \cdot c + (1 - TB) \cdot b $$

这种颜色表现模型能够根据距离调整物体的颜色，从而更好地模拟水下场景的视觉效果。

#### **4.3 基于物理的密度控制策略**

在传统的3DGS方法中，高斯点的分布是通过2D位置梯度动态调整的。然而，在水下环境中，由于光的衰减，远距离区域的高斯点颜色梯度会变得非常小，导致这些区域的高斯点无法有效分裂和克隆，从而出现模糊伪影。

为了解决这一问题，本文提出了一种基于物理的密度控制策略。具体来说，通过补偿衰减因子（TD）对梯度计算的影响，使得高斯点能够在远距离区域更有效地分裂和克隆。此外，本文还引入了像素覆盖数量的考虑，避免仅依赖视图数量来计算平均2D位置梯度，从而进一步提高了远距离区域的重建质量。

#### **4.4 二值运动掩码（BMM）**

水下场景中动态物体的存在会引入重建伪影，影响重建结果的质量。为了解决这一问题，本文引入了二值运动掩码（BMM），通过检测和排除动态物体的影响，提高重建结果的鲁棒性。

BMM的计算过程如下：

1. **残差计算**：计算每个像素的残差（ϵ），即渲染图像与真实图像之间的差异。

2. **阈值判断**：根据残差的分布，设置阈值（Tϵ），将残差小于阈值的像素视为静态物体（inliers），其余像素视为动态物体（outliers）。

3. **空间平滑**：通过3×3扩散核（B）对掩码进行空间平滑处理，避免高频噪声的影响。

4. **局部分类**：根据每个8×8块的16×16邻域的平均值，进一步分类像素，确保掩码的准确性。

最终，BMM通过结合上述三种方法，生成一个鲁棒的掩码，用于排除动态物体的影响。

#### **4.5 损失函数**

为了优化模型参数，本文设计了一个综合损失函数，包括以下三个部分：

1. **重建损失（LRec）**：结合L1损失和结构相似性（D-SSIM）损失，用于优化重建图像的质量。

2. **深度监督损失（Lda）**：通过伪深度图（由DepthAnything生成）监督高斯点的深度信息，减少浮动物体（floaters）的影响。

3. **灰度世界假设损失（Lg）**：基于灰度世界假设，约束场景中物体的颜色分布，确保模型能够合理估计介质参数。

综合损失函数定义为：
$$ L = LRec + Lda + Lg $$

### **5. 实验验证**

#### **5.1 数据集**

本文在以下三个数据集上验证了UW-GS的有效性：

1. **SeaThru-NeRF**：包含四个不同海域的图像序列，经过白平衡增强处理。

2. **IW数据集**：包含中等深度水下场景的图像，提供动态物体掩码。

3. **S-UW数据集**：作者新收集的浅水水下视频数据集，包含四个不同场景，提供动态物体掩码。

#### **5.2 实现细节**

- **框架**：基于PyTorch实现。

- **初始化**：使用COLMAP初始化点云和相机位置。

- **训练**：在单个RTX 3090 GPU上进行训练，共15,000次迭代。前1,000次迭代仅优化深度损失，后续迭代同时优化高斯点属性和介质MLP。

#### **5.3 基线方法**

本文将UW-GS与以下基线方法进行了比较：

1. **Instant-NGP**：一种快速的神经图形原语方法。

2. **SeaThru-NeRF**：一种针对散射介质的神经辐射场方法。

3. **3DGS**：传统的3D高斯点绘制方法。

#### **5.4 评估指标**

使用以下三个指标评估重建质量：

1. **PSNR（峰值信噪比）**：越高越好。

2. **SSIM（结构相似性）**：越高越好。

3. **LPIPS（感知相似性）**：越低越好。

#### **5.5 实验结果**

- **SeaThru-NeRF数据集**：UW-GS在PSNR、SSIM和LPIPS指标上均优于基线方法，平均PSNR提升2.09dB和2.70dB（相比3DGS和SeaThru-NeRF）。

- **S-UW数据集**：UW-GS在多个场景中表现最佳，平均PSNR提升0.43dB和2.96dB（相比3DGS和SeaThru-NeRF）。

此外，UW-GS在处理动态物体方面表现出色，能够有效排除动态物体的影响，减少伪影。

### **6. 局限性**

尽管UW-GS在水下场景重建中取得了显著效果，但在浅水场景中，由于水面光线干扰较大，其性能提升不如深水场景明显。此外，BMM可能会不完美地分类动态物体，导致静态区域的重建质量略有下降。

### **7. 结论**

本文提出了一种新型的3D高斯点绘制方法（UW-GS），通过改进颜色表现模型、密度控制策略和动态内容处理，显著提升了水下场景重建的质量。实验结果表明，UW-GS在多个水下数据集上均优于现有的方法，为水下环境探索和研究提供了新的技术手段。

### **8. 未来工作**

未来的研究方向可能包括：

1. 进一步优化浅水场景的重建性能。

2. 探索更多的物理模型和数据增强方法，以提高模型的泛化能力。

3. 将UW-GS应用于更广泛的水下应用场景，如实时水下导航和动态场景重建。



# 方法部分详解

## **3. 方法（Method）**

### **3.1 问题定义（Problem Formulation）**

UW-GS 是基于 3D 高斯点绘制（3DGS）的一种改进方法，旨在解决水下场景重建中的挑战。3DGS 是一种点云表示方法，通过一组高斯点（Gaussians）来表示 3D 场景。每个高斯点由以下参数定义：

- **中心位置** $ \mu $  

- **3D 协方差矩阵** $ \Sigma $  

- **透明度（Opacity）** $ \alpha $  

- **视图依赖的颜色（View-dependent color）** $ c $，通常用球谐函数（Spherical Harmonics, SH）表示。

在渲染时，这些高斯点被投影到 2D 空间，通过 α 混合生成最终图像颜色：

$$ C = \sum_{i=1}^{N} \alpha_i c_i \prod_{j=1}^{i-1} (1 - \alpha_j) $$

其中 $ N $ 是高斯点的数量。

然而，传统的 3DGS 方法在水下环境中表现不佳，主要原因是：

1. 水下光的吸收和散射会导致颜色失真和对比度下降。

2. 动态物体（如游动的鱼）会引入重建伪影。

3. 远距离物体的颜色信息因光衰减而变得稀疏，导致重建结果模糊。

为了解决这些问题，UW-GS 引入了以下创新模块：

### **3.2 新的颜色表现模型（Color Appearance Model）**

传统的 3DGS 方法使用球谐函数（SH）来表示高斯点的颜色，这种方法假设场景处于透明介质中，无法处理水下的光衰减和散射。UW-GS 提出了一种新的颜色表现模型，通过多层感知机（MLP）估计水介质参数，并根据这些参数调整高斯点的颜色。

具体来说，MLP 以高斯点的深度（$ z $）和视图方向（$ \theta $）为输入，估计以下参数：

- **衰减因子（TD）**：表示直接光的衰减。

- **背景光因子（TB）**：表示散射光的影响。

- **介质系数（βd, βb）**：用于调节衰减和散射的影响。

- **背景光颜色（b）**：表示无限远处的背景光颜色。

通过这些参数，可以计算出修正后的高斯点颜色（$ c_m $）：

$$ c_m = TD \cdot c + (1 - TB) \cdot b $$

这种颜色表现模型能够根据距离调整物体的颜色，从而更好地模拟水下场景的视觉效果。例如，随着物体距离相机的增加，其颜色会逐渐接近背景光颜色，同时对比度会降低。

### **3.3 基于物理的密度控制策略（Physics-based Density Control）**

在传统的 3DGS 方法中，高斯点的分布是通过 2D 位置梯度动态调整的。然而，在水下环境中，由于光的衰减，远距离区域的高斯点颜色梯度会变得非常小，导致这些区域的高斯点无法有效分裂和克隆，从而出现模糊伪影。

为了解决这一问题，UW-GS 提出了一种基于物理的密度控制策略。具体来说，通过补偿衰减因子（TD）对梯度计算的影响，使得高斯点能够在远距离区域更有效地分裂和克隆。

具体实现如下：

1. **梯度补偿**：在计算 2D 位置梯度时，引入衰减因子的逆（$ \frac{1}{TD} $），以补偿光衰减对梯度的影响：

   $$ \delta L_{\text{Rec}} = \frac{\delta L_{\text{Rec}}}{TD} $$

   这样可以确保远距离区域的高斯点能够获得足够的梯度信息，从而进行有效的分裂和克隆。

2. **像素覆盖数量的考虑**：为了避免仅依赖视图数量来计算平均 2D 位置梯度，UW-GS 引入了像素覆盖数量的考虑。通过计算高斯点在 2D 空间中覆盖的像素数量，而不是单纯依赖视图数量，从而进一步提高了远距离区域的重建质量。

3. **局部调整**：为了处理靠近相机的浮动物体（floaters），UW-GS 引入了一个与深度相关的缩放因子（$ S_z $），用于局部调整 2D 位置梯度：

   $$ \delta L_{\text{Rec}} = S_z \cdot \delta L_{\text{Rec}} $$

   这样可以有效抑制靠近相机的浮动物体，而不影响其他区域的重建质量。

通过这些改进，UW-GS 能够在远距离区域生成更密集的高斯点，从而减少模糊伪影，提高重建质量。

### **3.4 二值运动掩码（Binary Motion Mask, BMM）**

水下场景中动态物体的存在会引入重建伪影，影响重建结果的质量。为了解决这一问题，UW-GS 引入了二值运动掩码（BMM），通过检测和排除动态物体的影响，提高重建结果的鲁棒性。

BMM 的计算过程如下：

1. **残差计算**：计算每个像素的残差（$ \epsilon $），即渲染图像与真实图像之间的差异：

   $$ \epsilon = \| \hat{I} - I \|_2 $$

   其中 $ \hat{I} $ 是渲染图像，$ I $ 是真实图像。

2. **阈值判断**：根据残差的分布，设置阈值（$ T_\epsilon $），将残差小于阈值的像素视为静态物体（inliers），其余像素视为动态物体（outliers）。

3. **空间平滑**：通过 3×3 扩散核（$ B $）对掩码进行空间平滑处理，避免高频噪声的影响：

   $$ \omega_2 = \omega_1 * B \geq T_* $$

   其中 $ \omega_1 $ 是初始掩码，$ T_* $ 是平滑后的阈值。

4. **局部分类**：根据每个 8×8 块的 16×16 邻域的平均值，进一步分类像素，确保掩码的准确性：

   $$ \omega_3(R_{8 \times 8}) = \omega_2(R_{16 \times 16}) \geq T_R $$

   其中 $ T_R $ 是局部分类的阈值。

最终，BMM 通过结合上述三种方法，生成一个鲁棒的掩码，用于排除动态物体的影响。在训练过程中，BMM 被应用于重建损失函数中，从而提高重建结果的鲁棒性。

### **3.5 损失函数（Loss Function）**

为了优化模型参数，UW-GS 设计了一个综合损失函数，包括以下三个部分：

1. **重建损失（Reconstruction Loss, $ L_{\text{Rec}} $）**  

   结合 L1 损失和结构相似性（D-SSIM）损失，用于优化重建图像的质量：

   $$ L_{\text{Rec}} = \lambda \cdot \omega \cdot L_1 + (1 - \lambda) \cdot \omega \cdot L_{\text{D-SSIM}} $$

   其中 $ \lambda $ 是损失权重，$ \omega $ 是二值运动掩码。

2. **深度监督损失（Depth-supervised Loss, $ L_{\text{da}} $）**  

   通过伪深度图（由 DepthAnything 生成）监督高斯点的深度信息，减少浮动物体的影响：

   $$ L_{\text{da}} = \lambda_d L_d + \lambda_{\text{ca}} L_{\text{ca}} $$

   其中：

   - $ L_d $ 是深度监督的 L1 损失：

     $$ L_d = \| \hat{D} - D \| $$

   - $ L_{\text{ca}} $ 是通道深度对齐损失，基于水下图像形成模型，约束深度信息：

     $$ L_{\text{ca}} = \sum_{x \in \{r,g,b\}} \sum_{y \in \{d,b\}} \| \hat{z}_{y,x} - z \| $$

     其中 $ \hat{z}_{y,x} = -\log(T_{y,x}) / \beta_y $。

3. **灰度世界假设损失（Gray-world Assumption Loss, $ L_g $）**  
   基于灰度世界假设，约束场景中物体的颜色分布，确保模型能够合理估计介质参数：

   $$ L_g = \sum_{x \in \{r,g,b\}} \| \mu(J_x) - 0.5 \|_2^2 $$

   其中 $ \mu(J_x) $ 是通道 $ x $ 的平均值。

综合损失函数定义为：

$$ L = L_{\text{Rec}} + L_{\text{da}} + L_g $$

通过结合上述损失函数，UW-GS 能够在训练过程中同时优化重建质量、深度信息和颜色分布，从而提高水下场景重建的精度和鲁棒性。



## **方法总结**

UW-GS 通过以下创新点显著提升了水下场景重建的质量：

1. **新型颜色表现模型**：通过 MLP 估计水介质参数，并根据这些参数调整高斯点的颜色，从而更好地模拟水下场景的颜色变化。

2. **基于物理的密度控制策略**：通过补偿光衰减对梯度计算的影响，使得高斯点能够在远距离区域更有效地分裂和克隆，减少模糊伪影。

3. **二值运动掩码（BMM）**：通过检测和排除动态物体的影响，提高重建结果的鲁棒性。

4. **综合损失函数**：结合重建损失、深度监督损失和灰度世界假设损失，优化模型参数，提高重建精度。

这些创新模块共同作用，使得 UW-GS 在多个水下数据集上表现出色，显著优于现有的方法。

