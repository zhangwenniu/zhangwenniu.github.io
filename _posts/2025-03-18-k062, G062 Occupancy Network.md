---
layout: mypost
title: k062, G062 Occupancy Networks, Learning 3D Reconstruction in Function Space
categories: []
---

### 论文重点与难点

#### 重点

`1.` **提出Occupancy Networks（ONet）**：

   - ONet是一种新的基于深度学习的3D重建表示方法，通过将3D表面表示为深度神经网络分类器的连续决策边界，能够隐式地表示3D几何形状。

   - 与传统方法（如体素、点云、网格）相比，ONet能够在不牺牲细节的情况下，以无限分辨率表示3D形状，同时大幅减少内存占用。

`2.` **高效编码与重建能力**：

   - 通过随机采样3D空间中的点，并利用交叉熵损失函数训练网络，ONet能够高效地从各种输入（如单视图图像、噪声点云、低分辨率体素）中推断出3D结构。

![fig.3](OccNetwork.fig.3.png)

> 图3：离散与连续。我们的连续表示（右）与不同分辨率的体素化（左）的定性比较。请注意，我们的表示编码了在基于体素的表示中丢失的细节。

   - 在实验中，ONet在单视图3D重建、点云补全和体素超分辨率等任务上均取得了与现有方法相当甚至更好的结果。

`3.` **多分辨率等值面提取算法（MISE）**：

   - 为了从训练好的ONet中提取高质量的3D网格，作者提出了一种基于八叉树的多分辨率等值面提取算法。

   - 该算法通过逐步细分网格，能够在不密集评估所有点的情况下高效提取高分辨率的3D网格，并利用Marching Cubes算法最终生成闭合的3D表面。

`4.` **广泛的实验验证**：

   - 作者通过在ShapeNet数据集上的实验，展示了ONet在表示复杂3D形状、从单视图图像重建、点云补全和体素超分辨率等任务上的有效性。

   - 实验结果表明，ONet在体积交并比（IoU）、Chamfer距离和法线一致性等指标上均优于或接近现有方法。

#### 难点

`1.` **连续表示的训练与采样策略**：

   - ONet的核心是通过神经网络预测任意3D点的占据概率，这需要设计有效的采样策略以确保网络能够学习到准确的决策边界。

   - 论文尝试了多种采样策略（如均匀采样、等比例采样、表面采样），最终发现均匀采样效果最好，但其原因和潜在的优化空间仍需进一步研究。

`2.` **多分辨率等值面提取的实现复杂性**：

   - MISE算法虽然能够高效提取高分辨率网格，但其实现涉及八叉树的动态构建和细分，需要处理复杂的边界条件和内存管理问题。

   - 此外，算法的性能和最终网格质量高度依赖于初始分辨率的选择和细分策略的优化。

`3.` **从不同输入模态中学习的泛化能力**：

   - ONet需要从单视图图像、噪声点云等不同模态的输入中学习3D结构，这要求网络能够处理输入的多样性和不确定性。

![fig.3](OccNetwork.fig.3.png)

> 图3：离散与连续。我们的连续表示（右）与不同分辨率的体素化（左）的定性比较。请注意，我们的表示编码了在基于体素的表示中丢失的细节。

   - 例如，在单视图3D重建任务中，网络需要从有限的2D信息中推断出完整的3D形状，这对网络的泛化能力和先验知识学习提出了较高要求。

`4.` **无监督学习与生成能力的提升**：

   - 在无监督生成任务中，ONet通过学习3D形状的潜在空间来生成新的3D模型，但如何进一步提高生成模型的质量和多样性是一个挑战。

   - 论文中展示了ONet在几个类别上的生成结果，但生成的模型仍存在一定的局限性，如细节缺失或拓扑不准确等问题。

`5.` **计算效率与内存占用的平衡**：

   - 尽管ONet在理论上能够表示无限分辨率的3D形状，但在实际训练和推理过程中，网络的深度和宽度需要在计算效率和表示能力之间做出权衡。

   - 例如，使用更深或更宽的网络可以提高表示能力，但会显著增加训练时间和内存占用。

# 论文详细解读

Occupancy Networks: Learning 3D Reconstruction in Function Space

## 1 研究背景与动机

- **3D重建的挑战**：在2D图像领域，深度学习已经取得了巨大成功，但在3D重建中，缺乏一种既高效又能够表示任意拓扑结构的3D表示方法。现有方法（如体素、点云、网格）存在局限性，例如体素表示内存占用大，点云缺乏拓扑结构，网格表示难以处理复杂拓扑。

- **Occupancy Networks（ONet）的提出**：本文提出了一种新的3D表示方法——Occupancy Networks，通过深度神经网络隐式地表示3D表面，将3D几何表示为一个连续的决策边界，从而在不牺牲细节的情况下实现高分辨率的3D重建。

## 2 方法概述

- **核心思想**：将3D表面表示为一个连续的占据函数（occupancy function），该函数将3D空间中的每个点映射为一个占据概率（0表示不占据，1表示占据）。通过深度神经网络$$f_\theta: \mathbb{R}^3 \times X \rightarrow [0, 1]$$来预测任意点的占据概率，从而隐式地表示3D形状。

- **训练过程**：

  - 随机采样3D空间中的点，并根据其是否在物体内部标记为占据或不占据。

  - 使用交叉熵损失函数$$L(f_\theta(p_i, x), o_i)$$来训练网络，其中$$p_i$$是采样点，$$x$$是输入（如图像、点云等），$$o_i$$是真实占据状态。

  - 通过条件批量归一化（Conditional Batch Normalization, CBN）和ResNet结构来提高网络的表达能力。

- **推理过程**：

  - 使用多分辨率等值面提取算法（MISE）从训练好的网络中提取高分辨率的3D网格。

  - MISE通过八叉树逐步细分网格，仅对可能包含表面的区域进行评估，从而高效地提取等值面。

  - 最终利用Marching Cubes算法生成闭合的3D网格，并通过梯度信息优化网格质量。

## 3 实验与结果

- **实验设置**：

  - 使用ShapeNet数据集进行训练和测试。

  - 评估指标包括体积交并比（IoU）、Chamfer距离和法线一致性。

  - 与多种现有方法（如3D-R2N2、PSGN、Pixel2Mesh、AtlasNet等）进行比较。

- **实验结果**：

![fig.3](OccNetwork.fig.3.png)

> 图3：离散与连续。我们的连续表示（右）与不同分辨率的体素化（左）的定性比较。请注意，我们的表示编码了在基于体素的表示中丢失的细节。

  - **单视图3D重建**：

    - ONet在IoU和法线一致性上优于所有基线方法，表明其能够更准确地重建复杂拓扑结构。

    - 例如，在“椅子”类别上，ONet的IoU为0.89，而3D-R2N2仅为0.439。

  - **点云补全**：

    - ONet在IoU和Chamfer距离上均优于基线方法，表明其能够从噪声点云中准确重建出完整的3D网格。

    - 例如，ONet的IoU为0.778，而DMC为0.674。

  - **体素超分辨率**：

    - ONet能够从低分辨率体素中重建出高分辨率的3D网格，显著提升了IoU和法线一致性。

    - 例如，输入体素的IoU为0.631，ONet输出的IoU提升至0.703。

  - **无监督生成**：

    - ONet能够生成高质量的3D模型，并在不同类别上展示了良好的生成能力。

    - 通过随机采样潜在空间，ONet可以生成新的3D形状，展示了其生成能力。

## 4 方法细节与关键贡献

- **连续表示的优势**：

  - 与体素表示相比，ONet的内存占用不随分辨率增加而显著增长，能够表示任意分辨率的3D形状。

  - 与点云和网格表示相比，ONet不需要额外的后处理步骤来生成闭合的3D网格。

- **多分辨率等值面提取（MISE）**：

  - MISE算法通过八叉树逐步细分网格，仅对可能包含表面的区域进行评估，从而高效地提取高分辨率的3D网格。

  - 该算法能够在不密集评估所有点的情况下生成高质量的3D网格，同时避免了Marching Cubes算法的离散化误差。

- **网络架构**：

  - 使用ResNet结构和条件批量归一化（CBN）来提高网络的表达能力。

  - 不同输入模态（如图像、点云、体素）使用不同的编码器，例如ResNet18用于图像，PointNet用于点云。

## 5 讨论与未来工作

- **局限性**：

  - ONet的训练依赖于高质量的3D标注数据，对于复杂场景或稀疏数据的泛化能力有待进一步验证。

  - 生成的3D网格质量在某些情况下仍存在细节缺失或拓扑错误，尤其是在复杂形状上。

- **未来工作**：

  - 探索更高效的采样策略和网络架构，以进一步提高ONet的表示能力和训练效率。

  - 将ONet应用于更复杂的场景重建任务，例如多视图重建和动态场景重建。

  - 研究如何结合其他先验信息（如语义信息、物理约束）来进一步提升3D重建的质量。

## 6 总结

本文提出的Occupancy Networks为3D重建提供了一种新的表示方法，通过隐式地表示3D表面，ONet能够在不牺牲细节的情况下实现高分辨率的3D重建。实验结果表明，ONet在多种任务上均优于现有方法，展示了其在学习基3D任务中的潜力。

# 论文方法部分详细讲解

### 3.1 Occupancy Networks

- **核心思想**：将3D物体的表面表示为一个**连续的占据函数** $$o: \mathbb{R}^3 \rightarrow \{0, 1\}$$，其中0表示空间中的点不在物体内部，1表示在物体内部。该函数可以通过深度神经网络来近似。

- **网络定义**：定义一个神经网络 $$f_\theta: \mathbb{R}^3 \times X \rightarrow [0, 1]$$，其中 $$X$$ 是输入（如图像、点云或体素），$$p \in \mathbb{R}^3$$ 是3D空间中的点，$$f_\theta(p, x)$$ 表示点 $$p$$ 在给定输入 $$x$$ 下的占据概率。

- **条件输入**：通过将输入 $$x$$ 编码为特征向量，并将其与3D点 $$p$$ 结合，使得网络能够根据输入条件预测占据概率。

### 3.2 Training

- **训练目标**：通过随机采样3D空间中的点，并使用交叉熵损失来训练网络，使其能够准确预测占据状态。

- **采样策略**：

  - 在训练时，对于每个输入 $$x$$，随机采样 $$K$$ 个点 $$p_{ij} \in \mathbb{R}^3$$，并计算这些点的占据概率。

  - 采用均匀采样策略，在物体的包围盒内随机采样点，并附加一个小的边界以确保覆盖整个物体。

- **损失函数**：

  - 定义批量损失函数为：

    
$$
L_B(\theta) = \frac{1}{\vert B\vert } \sum_{i=1}^{\vert B\vert } \sum_{j=1}^K \mathcal{L}(f_\theta(p_{ij}, x_i), o_{ij})
$$

其中，$$\mathcal{L}$$ 是交叉熵损失，$$o_{ij}$$ 是点 $$p_{ij}$$ 的真实占据状态。

- **概率潜变量模型**：

  - 引入编码器网络 $$g_\psi$$，将占据状态和位置编码为高斯分布的均值和方差。

  - 通过优化变分自编码器（VAE）的目标函数，训练网络学习数据的潜在表示：

    
$$
L_{\text{gen}} = \mathbb{E}_{q_\psi(z \vert p, o)}[\log p_\theta(o \vert p, z)] - \text{KL}(q_\psi(z \vert p, o) \| p_0(z))
$$

### 3.3 Inference

- **多分辨率等值面提取（MISE）**：

  - **初始化**：将3D空间离散化为初始分辨率（如 $$32^3$$），并评估网络 $$f_\theta(p, x)$$ 在这些点上的占据概率。

  - **标记与细分**：标记占据状态不同的体素为“活跃”，并将这些体素细分为8个子体素，继续评估新点的占据概率。

  - **迭代**：重复上述步骤，直到达到目标分辨率。

  - **网格提取**：在最终分辨率下，使用Marching Cubes算法提取等值面：

    
$$
\{p \in \mathbb{R}^3 \vert f_\theta(p, x) = \tau\}
$$

其中，$$\tau$$ 是阈值，用于确定表面的位置。

- **网格优化**：

  - 使用Fast-Quadric-Mesh-Simplification算法简化网格。

  - 利用网络的梯度信息优化网格顶点的位置，最小化以下损失：

    
$$
\sum_{k=1}^K (f_\theta(p_k, x) - \tau)^2 + \lambda \left\| \nabla_p f_\theta(p_k, x) - n(p_k) \right\|^2
$$

其中，$$n(p_k)$$ 是网格在点 $$p_k$$ 处的法线，$$\lambda$$ 是正则化参数。

### 3.4 Implementation Details

- **网络架构**：

  - 使用包含5个ResNet块的全连接网络作为占据网络。

  - 根据输入类型选择不同的编码器：ResNet18用于图像，PointNet用于点云，3D卷积网络用于体素。

- **训练细节**：

  - 使用Adam优化器进行训练。

  - 在训练过程中，通过验证集上的损失来选择最优的网络参数。

- **推理时间**：

  - 提取单个网格的平均时间为3秒。

### 总结

Occupancy Networks通过将3D表面表示为连续的占据函数，结合深度神经网络和多分辨率等值面提取算法，实现了高效且高分辨率的3D重建。该方法的关键在于如何通过采样策略和网络架构设计，高效地学习和提取3D几何信息。

# 原文翻译

占用网络：在函数空间中学习3D重建

**作者**：Lars Mescheder1, Michael Oechsle1,2, Michael Niemeyer1, Sebastian Nowozin3†, Andreas Geiger1  

**单位**：1 马克斯·普朗克智能系统研究所自主视觉组和图宾根大学  

2 ETAS GmbH, 斯图加特  

3 谷歌AI柏林  

**邮箱**：{firstname.lastname}@tue.mpg.de, nowozin@gmail.com  

## 摘要

随着深度神经网络的出现，基于学习的3D重建方法变得越来越流行。然而，与图像不同，在3D领域中没有一种既计算和内存高效，又能表示任意拓扑的高分辨率几何的规范表示。因此，许多最先进的基于学习的3D重建方法只能表示非常粗糙的3D几何，或仅限于特定领域。在本文中，我们提出了占用网络（Occupancy Networks），这是一种新的基于学习的3D重建方法表示。占用网络将3D表面隐式表示为深度神经网络分类器的连续决策边界。与现有方法相比，我们的表示在不占用过多内存的情况下，能够以无限分辨率编码3D输出。我们验证了我们的表示能够高效地编码3D结构，并且可以从各种类型的输入中推断出来。我们的实验表明，在从单张图像、噪声点云和粗糙离散体素网格进行3D重建的挑战性任务中，我们的方法在定性和定量上都取得了具有竞争力的结果。我们相信，占用网络将成为各种基于学习的3D任务中的有用工具。

## 1 引言

![fig.1](OccNetwork.fig.1.png)

> 图1：概述：现有的3D表示以不同方式离散化输出空间：（a）在体素表示中空间离散化，（b）在预测点中离散化，以及（c）在网格表示的顶点中离散化。相比之下，（d）我们提出将分类器$$f_\theta$$（例如深度神经网络）的连续决策边界视为3D表面，从而允许以任何分辨率提取3D网格。

最近，基于学习的3D重建方法变得越来越流行[4, 9, 23, 58, 75, 77]。与传统的多视角立体算法不同，学习模型能够编码关于3D形状空间的丰富先验信息，这有助于解决输入中的歧义。虽然生成模型最近在生成高分辨率逼真图像方面取得了显著成功[36, 47, 72]，但这种成功尚未在3D领域复制。与2D领域不同，社区尚未就一种既内存高效又能从数据中高效推断的3D输出表示达成一致。现有表示大致可以分为三类：体素表示[4, 19, 43, 58, 64, 69, 75]、点云表示[1, 17]和网格表示[34, 57, 70]，见图1。

![fig.1](OccNetwork.fig.1.png)

> 图1：概述：现有的3D表示以不同方式离散化输出空间：（a）在体素表示中空间离散化，（b）在预测点中离散化，以及（c）在网格表示的顶点中离散化。相比之下，（d）我们提出将分类器$$f_\theta$$（例如深度神经网络）的连续决策边界视为3D表面，从而允许以任何分辨率提取3D网格。

体素表示是像素在3D情况下的直接推广。然而，不幸的是，体素表示的内存占用随分辨率呈立方增长，因此限制了朴素实现只能处理$$32^3$$或$$64^3$$体素。虽然可以通过使用数据自适应表示（如八叉树[61, 67]）来减少内存占用，但这种方法导致复杂的实现，并且现有的数据自适应算法仍然局限于相对较小的$$256^3$$体素网格。点云[1, 17]和网格[34, 57, 70]已被引入作为深度学习的替代表示，使用适当的损失函数。然而，点云缺乏底层网格的连接结构，因此需要额外的后处理步骤来从模型中提取3D几何。现有的网格表示通常基于模板网格的变形，因此不允许任意拓扑。此外，这两种方法在标准前馈网络中可以可靠预测的点/顶点数量上受到限制。在本文中，我们提出了一种基于直接学习连续3D占用函数的新方法（图1d）。我们不是预测固定分辨率的体素化表示，而是预测完整的占用函数，使用神经网络$$f_\theta$$，该网络可以在任意分辨率下进行评估。这大大减少了训练期间的内存占用。在推理时，我们使用简单的多分辨率等值面提取算法从学习模型中提取网格，该算法在3D位置上可以轻松并行化。总之，我们的贡献如下：

• 我们引入了一种基于学习连续3D映射的新的3D几何表示。

• 我们展示了如何使用这种表示从各种输入类型重建3D几何。

• 我们通过实验验证了我们的方法能够生成高质量的网格，并证明它在与最先进方法的比较中表现优异。

## 2 相关工作

现有的基于学习的3D重建工作可以根据其生成的输出表示大致分为体素表示、点云表示和网格表示。

**体素表示**：由于其简单性，体素是判别性[45, 55, 63]和生成性[9, 23, 58, 64, 75, 77]3D任务中最常用的表示。早期的工作考虑了使用在体素网格上操作的3D卷积神经网络从单张图像重建3D几何的问题[9, 68, 77]。然而，由于内存需求，这些方法仅限于相对较小的$$32^3$$体素网格。虽然最近的工作[74, 76, 79]将3D卷积神经网络应用于高达$$128^3$$的分辨率，但这只能在浅层架构和小批量大小下实现，这导致训练速度较慢。从多个输入视图重建3D几何的问题在[31, 35, 52]中得到了考虑。Ji等人[31]和Kar等人[35]将相机参数与输入图像一起编码为3D体素表示，并应用3D卷积从多个视图重建3D场景。Paschalidou等人[52]引入了一种架构，该架构从多个图像预测体素占用率，利用多视图几何约束[69]。其他工作将体素表示应用于学习3D形状的生成模型。这些方法大多基于变分自编码器[39, 59]或生成对抗网络[25]。这两种方法分别在[4, 58]和[75]中得到了应用。由于体素表示的高内存需求，最近的工作提出了以多分辨率方式重建3D对象[28, 67]。然而，由此产生的方法通常实现复杂，并且需要多次遍历输入以生成最终的3D模型。此外，它们仍然局限于相对较小的$$256^3$$体素网格。为了实现亚体素精度，一些工作[12,42,60]提出了预测截断有符号距离场（TSDF）[11]，其中3D网格中的每个点存储到最近3D表面点的截断有符号距离。然而，与占用表示相比，这种表示通常更难学习，因为网络必须推理3D空间中的距离函数，而不仅仅是将体素分类为占用或未占用。此外，这种表示仍然受到底层3D网格分辨率的限制。

**点云表示**：3D点云是3D几何的一种有趣的替代表示，广泛应用于机器人和计算机图形学社区。Qi等人[54, 56]开创了点云作为判别性深度学习任务的表示。他们通过对每个点独立应用全连接神经网络，然后进行全局池化操作，实现了排列不变性。Fan等人[17]将点云作为3D重建的输出表示引入。然而，与其他表示不同，这种方法需要额外的非平凡后处理步骤[3, 6, 37, 38]来生成最终的3D网格。

![fig.3](OccNetwork.fig.3.png)

> 图3：离散与连续。我们的连续表示（右）与不同分辨率的体素化（左）的定性比较。请注意，我们的表示编码了在基于体素的表示中丢失的细节。

**网格表示**：网格首先被考虑用于判别性3D分类或分割任务，通过在网格的顶点和边构成的图上应用卷积[5, 27, 71]。最近，网格也被考虑作为3D重建的输出表示[26,33,41,70]。不幸的是，大多数这些方法容易生成自相交的网格。此外，它们只能生成具有简单拓扑的网格[70]，需要来自同一对象类的参考模板[33, 41, 57]或无法保证封闭表面[26]。Liao等人[43]提出了行进立方体算法[44]的端到端可学习版本。然而，他们的方法仍然受到底层3D网格内存需求的限制，因此也局限于$$32^3$$体素分辨率。与上述方法相比，我们的方法能够生成高分辨率的封闭表面，没有自相交，并且不需要来自同一对象类的模板网格作为输入。这一想法与经典的水平集[10, 14, 50]多视图3D重建方法[18,24,32,40,53,78]相关。然而，我们的方法不是求解微分方程，而是使用深度学习来获得更具表现力的表示，这种表示可以自然地集成到端到端学习管道中。

## 3. 方法

在本节中，我们首先介绍占用网络，将其作为三维几何的一种表示形式。然后描述如何学习一个模型，该模型能从点云、单张图像和低分辨率体素表示等各种形式的输入中推断出这种表示。最后，我们阐述一种在测试阶段从模型中提取高质量三维网格的技术。 

### 3.1 占用网络

理想情况下，我们不仅希望像在体素表示中那样，在固定的离散三维位置上讨论占用情况，还希望在三维空间 $$\mathbb{R}^3$$ 中的每一个可能的三维点 $$p$$ 上进行讨论。我们将由此得到的函数


$$
o : \mathbb{R}^3 \to \{0, 1\} \tag{1}
$$

称为三维物体的占用函数。我们的关键见解是，可以用一个神经网络来近似这个三维函数，该神经网络为三维空间 $$\mathbb{R}^3$$ 中的每个位置 $$p$$ 分配一个介于 0 和 1 之间的占用概率。请注意，这个网络相当于一个用于二分类的神经网络，不同之处在于我们关注的是隐含表示物体表面的决策边界。

当使用这样一个网络，基于对某个物体的观测（例如图像、点云等）来对该物体进行三维重建时，我们必须根据输入对其进行条件设定。幸运的是，我们可以利用以下简单的函数等价关系：一个以观测值 $$x \in \mathcal{X}$$ 为输入，输出是从 $$p \in \mathbb{R}^3$$ 到 $$\mathbb{R}$$ 的函数，可以等价地用一个以 $$(p, x) \in \mathbb{R}^3 \times \mathcal{X}$$ 为输入并输出一个实数的函数来描述。后者可以简单地用一个神经网络 $$f_{\theta}$$ 参数化，该神经网络以 $$(p, x)$$ 为输入，并输出一个表示占用概率的实数：


$$
f_{\theta} : \mathbb{R}^3 \times \mathcal{X} \to [0, 1] \tag{2}
$$

我们将这个网络称为占用网络。 

### 3.2 训练

为了学习神经网络 $$f_{\theta}(p, x)$$ 的参数 $$\theta$$，我们在目标物体的三维包围体中随机采样点：对于训练批次中的第 $$i$$ 个样本，我们采样 $$K$$ 个点 $$p_{ij} \in \mathbb{R}^3$$，其中 $$j = 1, \ldots, K$$。然后我们在这些位置评估小批量损失 $$\mathcal{L}_{\mathcal{B}}$$：


$$
\mathcal{L}_{\mathcal{B}}(\theta)=\frac{1}{\vert \mathcal{B}\vert } \sum_{i = 1}^{\vert \mathcal{B}\vert } \sum_{j = 1}^{K} \mathcal{L}(f_{\theta}(p_{ij}, x_{i}), o_{ij}) \tag{3}
$$

这里，$$x_{i}$$ 是批次 $$\mathcal{B}$$ 中的第 $$i$$ 个观测值，$$o_{ij} \equiv o(p_{ij})$$ 表示点 $$p_{ij}$$ 处的真实占用情况，$$\mathcal{L}(\cdot, \cdot)$$ 是交叉熵分类损失。

我们方法的性能取决于用于选取训练所用位置 $$p_{ij}$$ 的采样方案。在4.6节中，我们进行了详细的消融研究，比较了不同的采样方案。在实践中，我们发现，在物体包围盒内均匀采样，并额外添加一个小的填充区域，能得到最佳结果。

我们的三维表示也可用于学习概率潜在变量模型。为了实现这一目标，我们引入一个编码器网络 $$g_{\psi}(\cdot)$$，它以位置 $$p_{ij}$$ 和占用情况 $$o_{ij}$$ 作为输入，并预测潜在变量 $$z \in \mathbb{R}^L$$ 上的高斯分布 $$q_{\psi}(z\vert (p_{ij}, o_{ij})_{j = 1:K})$$ 的均值 $$\mu_{\psi}$$ 和标准差 $$\sigma_{\psi}$$ 作为输出。我们对生成模型 $$p((o_{ij})_{j = 1:K}\vert (p_{ij})_{j = 1:K})$$ 的负对数似然的下界进行优化[21, 39, 59]：


$$
\begin{align*}
\mathcal{L}_{\mathcal{B}}^{\text{gen}}(\theta, \psi) &=\frac{1}{\vert \mathcal{B}\vert } \sum_{i = 1}^{\vert \mathcal{B}\vert } \left[\sum_{j = 1}^{K} \mathcal{L}(f_{\theta}(p_{ij}, z_{i}), o_{ij}) \right.\\
&\left.+\text{KL}(q_{\psi}(z\vert (p_{ij}, o_{ij})_{j = 1:K}) \| p_{0}(z))\right] \tag{4}
\end{align*}
$$

其中 $$\text{KL}$$ 表示 KL 散度，$$p_{0}(z)$$ 是潜在变量 $$z_{i}$$ 的先验分布（通常是高斯分布），$$z_{i}$$ 是根据 $$q_{\psi}(z_{i}\vert (p_{ij}, o_{ij})_{j = 1:K})$$ 采样得到的。 

### 3.3 推理

![fig.2](OccNetwork.fig.2.png)

> 图2：多分辨率等值面提取：我们首先标记在给定分辨率下已经被评估为占用（红色圆圈）或未占用（青色菱形）的所有点。然后，我们确定所有既有占用又有未占用角落的体素，并将它们标记为活跃（浅红色），并将它们细分为8个子体素。接下来，我们评估由细分引入的所有新网格点（空圆圈）。重复前两个步骤，直到达到所需的输出分辨率。最后，我们使用行进立方体算法[44]提取网格，并使用一阶和二阶梯度信息简化和优化输出网格。

为了从训练好的占用网络中提取与新观测值对应的等值面，我们引入了多分辨率等值面提取（MISE）方法，这是一种分层等值面提取算法（图2）。通过逐步构建八叉树[30, 46, 66, 73]，MISE 使我们能够从占用网络中提取高分辨率网格，而无需密集计算高维占用网格中的所有点。

我们首先在初始分辨率下离散化体空间，并对该网格中的所有 $$p$$ 计算占用网络 $$f_{\theta}(p, x)$$。对于 $$f_{\theta}(p, x)$$ 大于或等于某个阈值$$^{2}$$ $$\tau$$ 的所有网格点 $$p$$，我们将其标记为被占用。接下来，对于至少有两个相邻网格点的占用预测不同的所有体素，我们将其标记为活跃体素。如果我们在当前分辨率下应用移动立方体算法，这些体素就是会与网格相交的体素。我们将所有活跃体素细分为8个子体素，并计算通过这种细分引入到占用网格中的所有新网格点。我们重复这些步骤，直到达到所需的最终分辨率。在最终分辨率下，我们应用移动立方体算法[44] 来提取近似等值面


$$
\{p \in \mathbb{R}^3 \mid f_{\theta}(p, x)=\tau\}. \tag{5}
$$

如果初始分辨率下的占用网格包含来自网格内部和外部的每个连通分量的点，我们的算法就能收敛到正确的网格。因此，选择足够高的初始分辨率以满足这个条件是很重要的。在实践中，我们发现几乎在所有情况下，$$32^3$$ 的初始分辨率就足够了。

通过移动立方体算法提取的初始网格可以进一步细化。第一步，我们使用快速二次网格简化算法$$^{3}$$ [20] 来简化网格。最后，我们使用一阶和二阶（即梯度）信息来细化输出网格。为了实现这一目标，我们从输出网格的每个面中随机采样点 $$p_{k}$$，并最小化损失


$$
\sum_{k = 1}^{K}(f_{\theta}(p_{k}, x)-\tau)^{2}+\lambda \left\|\frac{\nabla_{p} f_{\theta}(p_{k}, x)}{\|\nabla_{p} f_{\theta}(p_{k}, x)\|}-n(p_{k})\right\|^{2} \tag{6}
$$

其中 $$n(p_{k})$$ 表示网格在 $$p_{k}$$ 处的法向量。在实践中，我们将 $$\lambda$$ 设置为 0.01。最小化公式(6) 中的第二项使用了二阶梯度信息，并且可以使用双重反向传播 [15] 有效地实现。

请注意，最后这一步消除了移动立方体近似中的离散化伪影，如果我们直接预测基于体素的表示，这是不可能实现的。此外，我们的方法还可以通过简单地通过占用网络进行反向传播，有效地提取输出网格所有顶点的法向量。总的来说，我们的推理算法每个网格需要 3 秒。 

### 3.4 实现细节

我们使用一个包含5个残差网络（ResNet）块[29] 的全连接神经网络来实现占用网络，并使用条件批归一化[13, 16] 根据输入对其进行条件设定。根据输入类型的不同，我们采用不同的编码器架构。对于单视图三维重建，我们使用ResNet18架构[29]。对于点云数据，我们使用PointNet编码器[54]。对于体素化输入，我们使用三维卷积神经网络[45]。对于无条件网格生成，我们对编码器网络 $$g_{\psi}$$ 使用PointNet[54]。补充材料中提供了更多细节。 

## 4 实验

我们进行了三种类型的实验来验证所提出的占用网络。首先，我们通过检查网络从学习到的潜在嵌入中重建复杂3D形状的能力来分析占用网络的表示能力。这为我们提供了一个上限，即当我们的表示依赖于额外输入时可以实现的结果。其次，我们将占用网络依赖于图像、噪声点云和低分辨率体素表示，并将我们的方法与几种最先进的基线进行比较。最后，我们通过向我们的模型添加编码器并从中生成无条件样本来检查占用网络的生成能力。

**基线**：对于单张图像3D重建任务，我们将我们的方法与几种利用不同3D表示的最先进基线进行比较：我们评估了3D-R2N2[9]作为基于体素的方法，点集生成网络（PSGN）[17]作为基于点云的技术，以及Pixel2Mesh[70]和AtlasNet[26]作为基于网格的方法。对于点云输入，我们通过改变编码器来调整3D-R2N2和PSGN。作为基于网格的基线，我们使用最近在该任务上报告了最先进结果的深度行进立方体（DMC）[43]。对于体素超分辨率任务，我们评估了相对于输入的改进。

**数据集**：对于我们所有的实验，我们使用了Choy等人[9]的ShapeNet[7]子集。我们还使用了与Choy等人相同的体素化、图像渲染和训练/测试分割。此外，我们将训练集细分为训练集和验证集，在这些集上跟踪我们的方法和基线的损失，以确定何时停止训练。为了生成水密网格并确定一个点是否位于网格内部（例如，用于测量IoU），我们使用了Stutz等人[64]提供的代码。为了公平比较，我们从水密网格的表面采样点，而不是原始模型，作为PSGN[17]、Pixel2Mesh[70]和DMC[43]的ground truth。我们所有的评估都是相对于这些水密网格进行的。

**指标**：对于评估，我们使用了体积IoU、Chamfer-L1距离和法线一致性得分。体积IoU定义为两个网格的并集体积与交集体积的商。我们通过从边界体积中随机采样100k个点并确定这些点是否位于ground truth/预测网格的内部或外部，来获得交集和并集体积的无偏估计。Chamfer-L1距离定义为准确性和完整性指标的平均值。准确性指标定义为输出网格上的点到其ground truth网格上最近邻点的平均距离。完整性指标类似定义，但方向相反。我们通过从两个网格中随机采样100k个点并使用KD树来估计相应的距离，从而高效地估计这两个距离。与Fan等人[17]一样，我们使用当前对象边界框的最大边长的1/10作为单位1。最后，为了衡量方法捕捉高阶信息的能力，我们定义了一个法线一致性得分，作为一个网格中的法线与另一个网格中相应最近邻点的法线的平均绝对点积。

### 4.1 表示能力

![fig.4](OccNetwork.fig.4.png)

> 图4：IoU与分辨率。该图显示了体素化与ground truth网格的IoU（蓝色实线）与我们的连续表示（橙色实线）以及两种表示所需的每模型参数数量（虚线）的比较。请注意，与低分辨率体素表示相比，我们的表示相对于ground truth网格的IoU更大。同时，体素表示的参数数量随分辨率呈立方增长，而占用网络的参数数量与分辨率无关。

![fig.3](OccNetwork.fig.3.png)

> 图3：离散与连续。我们的连续表示（右）与不同分辨率的体素化（左）的定性比较。请注意，我们的表示编码了在基于体素的表示中丢失的细节。

在我们的第一个实验中，我们研究了占用网络在独立于输入编码的不准确性情况下表示3D几何的能力。我们在这个实验中试图回答的问题是，我们的网络是否能够学习到一种内存高效的3D形状表示，同时尽可能多地保留细节。这为我们提供了模型表示能力的估计，以及当我们的模型依赖于额外输入时可能期望的性能上限。类似于[67]，我们将每个训练样本嵌入到一个512维的潜在空间中，并训练我们的神经网络从该嵌入中重建3D形状。我们将我们的方法应用于ShapeNet数据集的“椅子”类别的训练分割。这个子集具有挑战性，因为它变化很大，并且许多模型包含高频细节。由于我们只对重建训练数据感兴趣，因此我们在这个实验中没有使用单独的验证集和测试集。对于评估，我们测量了与ground truth网格的体积IoU。定量结果以及与不同分辨率的体素表示的比较如图4所示。我们看到，占用网络（ONet）能够以0.89的高平均IoU忠实地表示整个数据集，而低分辨率的体素表示无法准确地表示网格。同时，占用网络能够以仅6M的参数编码所有4746个训练样本，且与分辨率无关。相比之下，体素表示的内存需求随分辨率呈立方增长。定性结果如图3所示。我们观察到，占用网络使我们能够表示在低分辨率体素化中丢失的3D几何细节。

### 4.2 单张图像3D重建

在我们的第二个实验中，我们将占用网络依赖于从随机相机位置获得的对象的额外视图。这个实验的目标是评估从复杂输入中推断占用函数的能力。虽然我们在ShapeNet数据集上训练和测试我们的方法，但我们也展示了KITTI[22]和Online Products数据集[49]的定性结果。

**ShapeNet**：在这个实验中，我们使用了一个在ImageNet数据集上预训练的ResNet-18图像编码器。为了公平比较，我们为3D-R2N2和PSGN5使用相同的图像编码器。对于PSGN，我们使用一个具有4层和每层512个隐藏单元的全连接解码器。最后一层将隐藏表示投影到一个3072维的向量，我们将其重塑为1024个3D点。由于我们只使用单个输入视图，我们移除了3D-R2N2中的循环网络。我们在PyTorch中重新实现了[70]的方法，紧密遵循作者提供的Tensorflow实现。对于[26]的方法，我们使用了作者的代码和预训练模型。

![fig.5](OccNetwork.fig.5.png)

> 图5：单张图像3D重建。输入图像显示在第一列，其他列显示了我们的方法与各种基线的结果。

![table.1](OccNetwork.table.1.png)

> 表1：单张图像3D重建。该表显示了我们的方法与基线在ShapeNet数据集上单张图像3D重建的数值比较。我们测量了与ground truth网格的IoU、Chamfer-L1距离和法线一致性。请注意，与之前的工作不同，我们计算的是与高分辨率网格的IoU，而不是粗糙的体素表示。除AtlasNet[26]外，所有方法均在Choy等人[9]的测试分割上进行评估。由于AtlasNet使用了预训练模型，我们在[9]和[26]的测试分割的交集上对其进行了评估。

对于所有方法，我们在验证集上跟踪损失和其他指标，并在目标指标达到最佳时停止训练。对于3D-R2N2和我们的方法，我们使用与ground truth网格的IoU作为目标指标，对于PSGN和Pixel2Mesh，我们使用与ground truth网格的Chamfer距离作为目标指标。为了提取最终网格，我们使用3D-R2N2的阈值0.4，如原始出版物[9]中所建议的。为了选择我们的方法的阈值参数$$\tau$$，我们在验证集上进行了网格搜索（见补充材料），发现$$\tau = 0.2$$在准确性和完整性之间提供了良好的平衡。我们的模型和基线的定性结果如图5所示。我们观察到，所有方法都能够捕捉输入图像的3D几何。然而，3D-R2N2产生了一个非常粗糙的表示，因此缺乏细节。相比之下，PSGN产生了一个高保真的输出，但缺乏连通性。因此，PSGN需要额外的有损后处理步骤来生成最终网格。Pixel2Mesh能够创建引人注目的网格，但在存在更复杂拓扑时经常遗漏孔洞。这种拓扑在ShapeNet数据集的“椅子”类别中很常见。同样，AtlasNet很好地捕捉了几何，但以自相交和重叠补丁的形式产生了伪影。相比之下，我们的方法能够捕捉复杂的拓扑，生成封闭的网格，并保留大多数细节。请参阅补充材料以获取更多高分辨率结果和失败案例。定量结果如表1所示。我们观察到，我们的方法在与ground truth网格的IoU和法线一致性方面取得了最高值。令人惊讶的是，虽然我们的方法没有像PSGN、Pixel2Mesh或AtlasNet那样针对Chamfer距离进行训练，但我们的方法在这个指标上也取得了良好的结果。请注意，无法评估PSGN或AtlasNet的IoU，因为它们不生成水密网格。

![fig.6](OccNetwork.fig.6.png)

> 图6：真实数据的定性结果。我们将训练好的模型应用于KITTI和Online Products数据集。尽管仅在合成数据上训练，我们的模型在真实数据上也能很好地泛化。

**真实数据**：为了测试我们的模型在真实数据上的泛化能力，我们将我们的网络应用于KITTI[22]和Online Products数据集[49]。为了捕捉KITTI和Online Products中视角的多样性，我们重新渲染了所有ShapeNet对象，并随机选择相机位置，并为此任务重新训练了我们的网络。对于KITTI数据集，我们还使用了[2]中提供的实例掩码来掩码和裁剪汽车区域。然后我们将这些图像输入到我们的神经网络中，以预测占用函数。一些选定的定性结果如图6a所示。尽管仅在合成数据上训练，我们观察到我们的方法在这个具有挑战性的环境中也能够生成逼真的重建。对于Online Products数据集，我们应用了相同的预训练模型。几个定性结果如图6b所示。再次，我们观察到，尽管仅在合成数据上训练，我们的方法在真实图像上也能很好地泛化。在Pix3D数据集[65]上的额外定量评估可以在补充材料中找到。

### 4.3 点云补全

![table.2](OccNetwork.table.2.png)

> 表2：点云3D重建。该表显示了我们的方法与基线在ShapeNet数据集上从点云进行3D重建的数值比较。我们测量了与ground truth网格的IoU、Chamfer-L1距离和法线一致性。

作为第二个条件任务，我们将我们的方法应用于从噪声点云重建网格的问题。为了实现这一目标，我们从每个（水密的）ShapeNet模型的表面子采样300个点，并使用均值为0、标准差为0.05的高斯分布对点云添加噪声。我们再次测量了与ground truth网格的IoU和Chamfer-L1距离。结果如表2所示。我们观察到，我们的方法在IoU和法线一致性方面取得了最高值，并且Chamfer-L1距离最低。请注意，所有数字都显著优于单张图像3D重建任务。这可以解释为，这个任务对于识别模型来说要容易得多，因为歧义较少，模型只需要填补空白。

### 4.4 体素超分辨率

![table.3](OccNetwork.table.3.png)

> 表3：体素超分辨率。该表显示了我们的方法与输入在ShapeNet数据集上的输出数值比较。

作为最后一个条件任务，我们将占用网络应用于3D超分辨率[62]。这里的任务是从该网格的粗糙$$32^3$$体素化重建高分辨率网格。结果如表3所示。我们观察到，与粗糙的输入网格相比，我们的模型显著提高了IoU、Chamfer-L1距离和法线一致性。请参阅补充材料以获取定性结果。

### 4.5 无条件网格生成

最后，我们将我们的占用网络应用于无条件网格生成，以无监督的方式在ShapeNet数据集的四个类别上分别训练它。

![fig.7](OccNetwork.fig.7.png)

> 图7：无条件3D样本。我们在ShapeNet数据集的“汽车”、“飞机”、“沙发”和“椅子”类别上训练的无监督模型的随机样本。我们看到，我们的模型能够捕捉3D对象的分布并生成引人注目的新样本。

我们的目标是探索我们的模型在表示3D模型的潜在空间方面的能力。一些样本如图7所示。事实上，我们发现我们的模型能够生成引人注目的新模型。在补充材料中，我们展示了我们的模型在潜在空间中的插值。

### 4.6 消融研究

在本节中，我们测试了模型的各个组件如何影响其在单张图像3D重建任务中的性能。

![table.4](OccNetwork.table.4.png)

> 表4：消融研究。当我们改变采样策略时，我们观察到在边界体积内均匀采样效果最好。同样，当我们改变架构时，我们发现带有条件批归一化的ResNet架构产生了最佳结果。

**采样策略的影响**：首先，我们检查了采样策略如何影响我们最终模型的性能。我们尝试了三种不同的采样策略：（i）在ground truth网格的边界体积内均匀采样2048个点（均匀采样），（ii）在网格内部和外部各采样1024个点（等量采样），以及（iii）均匀采样1024个点，并在网格表面采样1024个点加上标准差为0.1的高斯噪声（表面采样）。我们还通过将采样点数量从2048减少到64，检查了采样点数量的影响。结果如表4a所示。令我们惊讶的是，我们发现最简单的均匀采样策略效果最好。我们通过以下事实来解释这一点：其他采样策略引入了模型的偏差：例如，当在网格内部和外部采样等量点时，我们隐含地告诉模型每个对象的体积为0.5。事实上，当使用这种采样策略时，我们观察到模型输出中的增厚伪影。此外，我们发现将采样点数量从2048减少到64仍然可以带来良好的性能，尽管模型的表现不如使用2048个采样点训练的模型。

![table.4](OccNetwork.table.4.png)

> 表4：消融研究。当我们改变采样策略时，我们观察到在边界体积内均匀采样效果最好。同样，当我们改变架构时，我们发现带有条件批归一化的ResNet架构产生了最佳结果。

**架构的影响**：为了测试我们架构的各个组件的影响，我们测试了两种变体：（i）我们移除了条件批归一化，并在网络开始时用线性层替换它，该线性层将输入的编码投影到所需的隐藏维度，以及（ii）我们移除了解码器中的所有ResNet块，并用线性块替换它们。结果如表4b所示。我们发现这两个组件都有助于实现良好的性能。

## 5 结论

在本文中，我们引入了占用网络，这是一种新的3D几何表示。与现有表示不同，占用网络不受3D空间离散化的限制，因此可以用于表示逼真的高分辨率网格。我们的实验表明，占用网络具有很高的表现力，可以有效地用于监督和无监督学习。因此，我们相信占用网络是一种可以应用于各种3D任务的有用工具。

## 致谢

这项工作得到了英特尔智能系统网络和微软研究院通过其博士奖学金计划的支持。
