---
layout: mypost
title: k025 WaterSplatting, Fast Underwater 3D Scene Reconstruction Using Gaussian Splatting
categories: [3DGS, 水下]
---

如果有研究水下场景重建的研究者，可以通过邮箱zhangwenniu@163.com联系我，我目前创建了一个水下场景重建的交流群，欢迎感兴趣的研究者加入。

# 链接

- [Project Page](https://water-splatting.github.io/)

- [Paper Link](https://arxiv.org/pdf/2408.08206)

- [Github Link](https://github.com/water-splatting/water-splatting)

# 重点难点介绍

这篇论文的重点和难点主要集中在如何将3D高斯绘制（3DGS）与体积渲染相结合，以实现实时高效的水下场景重建，同时解决散射介质（如水）对重建效果的影响。以下是对论文重点和难点部分的详细分析：

## 论文的重点部分

### 1. **方法的核心创新：结合3DGS和体积渲染**
- **重点**：提出了一种新的方法，将3D高斯绘制（3DGS）用于显式表示场景的几何结构，同时引入一个体积场来表示散射介质（如水）。这种双表示方法既能利用3DGS的高效渲染能力，又能处理水下场景中的散射效应。
- **意义**：这种方法解决了传统3DGS无法处理半透明介质的问题，同时避免了NeRF方法训练和渲染速度慢的缺点。

### 2. **新的损失函数设计**
- **重点**：设计了一种新的损失函数 **LReg**，结合了加权L1损失和结构相似性损失（DSSIM），以更好地适应高动态范围（HDR）和低光照场景。
- **意义**：这种损失函数能够提升模型对暗部区域的细节处理能力，使重建结果更符合人类视觉感知。

### 3. **实验验证**
- **重点**：在真实水下数据集（SeaThru-NeRF 数据集）和模拟雾天场景上验证了方法的有效性。
- **意义**：通过与现有方法（如SeaThru-NeRF、ZipNeRF和3DGS）的对比，证明了WaterSplatting在渲染质量、训练速度和实时性方面的优势。

### 4. **实时渲染能力**
- **重点**：WaterSplatting实现了高效的水下场景重建，同时保持了实时渲染速度。
- **意义**：这使得该方法在实际应用中具有更大的潜力，例如水下机器人导航和虚拟现实体验。

## 论文的难点部分

### 1. **散射介质的建模**
- **难点**：水下场景中的散射效应（如光线的散射和吸收）使得传统的几何重建方法难以直接应用。如何准确地建模和渲染散射介质是一个关键问题。
- **解决方案**：作者通过引入一个单独的体积场来表示散射介质，并修改渲染方程来处理散射效应。这种方法需要精确估计散射介质的参数（如衰减系数和后向散射系数）。

### 2. **双表示的融合**
- **难点**：将3DGS的显式几何表示与体积场的散射介质表示相结合，需要在渲染过程中同时处理两种不同的表示方法。这涉及到复杂的渲染方程和优化问题。
- **解决方案**：作者通过在渲染过程中交替处理高斯点和体积段，实现了两种表示的融合。具体来说，他们通过计算每条光线的透射率，将几何和介质的贡献分别计算并合成。

### 3. **损失函数的设计**
- **难点**：传统的损失函数（如L1损失）在处理高动态范围和低光照场景时，可能会导致重建结果过于平滑，丢失细节。如何设计一个能够更好地适应这些场景的损失函数是一个挑战。
- **解决方案**：作者提出了一个新的损失函数 **LReg**，通过引入加权机制，提升对暗部区域的细节处理能力。此外，结合结构相似性损失（DSSIM）进一步优化了重建结果的结构一致性。

### 4. **实时性和效率的平衡**
- **难点**：在保持高质量重建的同时，如何实现高效的训练和实时渲染是一个关键问题。NeRF方法虽然能够重建高质量的场景，但训练和渲染速度慢；而3DGS虽然渲染速度快，但无法处理散射介质。
- **解决方案**：作者通过结合3DGS和体积渲染，实现了高效的水下场景重建。实验结果表明，WaterSplatting在保持高质量重建的同时，实现了接近3DGS的实时渲染速度。

## 总结
论文的重点在于提出了一种新的方法，通过结合3DGS和体积渲染，解决了水下场景重建中的散射介质问题，并设计了新的损失函数以提升重建质量。难点在于如何有效地融合两种表示方法、处理散射介质的建模，以及在保持高质量的同时实现高效的训练和实时渲染。作者通过一系列创新的方法和实验验证，成功解决了这些难点，为水下三维重建提供了一种高效且高质量的解决方案。

# 论文详细讲解

### 1. 作者信息
- **Huapeng Li**：苏黎世大学（University of Zurich），主要研究方向为计算机视觉和三维重建。  
- **Wenxuan Song**：苏黎世联邦理工学院（ETH Zurich），研究方向包括计算机图形学和实时渲染技术。  
- **Tianao Xu**：苏黎世联邦理工学院（ETH Zurich），专注于三维重建和神经渲染。  
- **Alexandre Elsig**：苏黎世联邦理工学院（ETH Zurich），研究方向为计算机视觉和机器学习。  
- **Jonas Kulhanek**：捷克技术大学（CTU in Prague）与苏黎世联邦理工学院（ETH Zurich），研究方向为计算机视觉和三维重建。

## 2. 研究背景与动机

水下三维场景重建是一个重要的研究领域，例如在水下机器人导航和虚拟现实体验中。传统的神经辐射场（NeRF）方法虽然可以重建场景，但训练和渲染速度慢，难以实时应用。3D高斯绘制（3DGS）虽然渲染速度快，但无法处理水下场景中的散射介质。因此，作者提出了一种结合两者优点的新方法——WaterSplatting。

## 3. 研究方法

### 3.1 3DGS与散射介质的结合

WaterSplatting 的核心思想是将场景的几何结构和散射介质分开表示。具体来说：
- **几何结构**：使用3DGS表示，通过高斯分布的点云来表示场景的表面。  
- **散射介质**：使用体积场表示，模拟水中的散射效应。  

作者通过修改渲染方程，将几何和介质的贡献分别计算，最终合成出完整的图像。这种方法不仅能够重建场景，还可以通过移除散射介质来恢复清晰的场景。

### 3.2 新的损失函数

为了更好地适应高动态范围（HDR）和低光照场景，作者设计了一种新的损失函数 **LReg**。它结合了像素级的加权L1损失和帧级的结构相似性损失（DSSIM），使模型在优化过程中更注重暗部区域的细节，从而更好地符合人类视觉感知。

## 4. 实验与结果

### 4.1 实验设置

作者在真实水下数据集（SeaThru-NeRF 数据集）和模拟的雾天场景上验证了方法。数据集包含多个真实水下场景的图像，模拟场景则通过在标准NeRF数据集上添加雾效生成。

### 4.2 对比方法

作者将WaterSplatting与多种现有方法（如SeaThru-NeRF、ZipNeRF和3DGS）进行了对比，使用PSNR、SSIM和LPIPS等指标评估重建质量，并记录了训练时间和渲染速度。

### 4.3 结果分析

实验结果表明：
- WaterSplatting在渲染质量上优于现有的NeRF方法，尤其是在复杂场景中表现更好。  
- WaterSplatting的渲染速度远快于传统NeRF方法，接近3DGS的实时渲染速度。  
- 在模拟场景中，WaterSplatting能够更好地恢复清晰场景，并生成更合理的深度图。

## 5. 限制与未来工作

尽管WaterSplatting取得了显著的成果，但仍有一些限制：
- 在处理远距离背景时，与介质的区分不够清晰。  
- 方法依赖于相机姿态的准确性，这在实际水下环境中可能难以获取。  
- 在训练视图覆盖不足的区域，模型的重建质量会下降。

未来，作者计划将这种方法扩展到更大规模的场景，并进一步优化对水和雾等介质的建模能力。

## 6. 总结

WaterSplatting通过结合3DGS和体积渲染，实现了高效且高质量的水下场景重建。它不仅在渲染质量上优于现有方法，还实现了实时渲染速度，为水下三维重建提供了一种新的解决方案。

# 论文方法部分介绍

论文的方法部分详细介绍了WaterSplatting的核心技术，即如何将三维高斯绘制（3D Gaussian Splatting, 3DGS）与体积渲染相结合，以实现高效的水下场景重建和实时渲染。以下是方法部分的详细介绍，包括关键的数学公式和实现细节。

## 3. 方法（Method）

### 3.1. 基础知识（Preliminaries）

**3.1.1 三维高斯绘制（3D Gaussian Splatting）**

3DGS是一种基于点的显式表示方法，通过一组可学习的高斯分布来表示场景的几何结构。每个高斯分布 $ G_i $ 由以下参数定义：
- 中心位置 $ \mu_i $  
- 协方差矩阵 $ \Sigma_i $  
- 不透明度 $ o_i $  
- 球谐系数 $ SH_i $（用于表示方向相关的颜色信息）

高斯分布的数学表达式为：
$$ G_i(p) = e^{-\frac{1}{2}(p - \mu_i)^T \Sigma_i^{-1} (p - \mu_i)} $$

在渲染过程中，每个高斯分布被投影到相机空间，并通过视图变换 $ W $ 和雅可比矩阵 $ J $ 进行变换，得到二维投影的均值 $ \hat{\mu}_i $ 和协方差矩阵 $ \hat{\Sigma}_i $：
$$ \hat{\Sigma}_i = (JW \Sigma_i W^T J^T)_{1:2,1:2} $$
$$ \hat{\mu}_i = (W \mu_i)_{1:2} $$

每个像素的颜色通过高斯分布的alpha混合计算得到：
$$ C = \sum_{i=1}^{N} c_i \alpha_i \prod_{j=1}^{i-1} (1 - \alpha_j) $$
其中，$ \alpha_i = \sigma(o_i) \cdot \hat{G}_i(p) $，$ \sigma(\cdot) $ 是Sigmoid函数，$ c_i $ 是高斯分布的颜色。

**3.1.2 散射介质的渲染模型**

在散射介质（如水）中，图像的形成模型可以表示为：
$$ I = O \cdot e^{-\beta_D(v_D) \cdot z} + B_\infty \cdot (1 - e^{-\beta_B(v_B) \cdot z}) $$
其中：
- $ O $ 是无介质时的清晰场景图像。  
- $ B_\infty $ 是无限远处的后向散射颜色。  
- $ \beta_D $ 和 $ \beta_B $ 分别是直接光和后向散射光的衰减系数。  
- $ v_D $ 和 $ v_B $ 分别表示直接光和后向散射光的依赖因素，如深度 $ z $、反射率、环境光和水的散射特性。

### 3.2. 方法：结合3DGS与介质建模（Splatting with Medium）

**3.2.1 渲染模型的改进**

WaterSplatting的核心思想是将3DGS的显式几何表示与体积场的散射介质表示相结合。具体来说，渲染方程被扩展为：
$$ C(r) = \int_{0}^{\infty} T(s) \left[ \sigma_{\text{obj}}(s) c_{\text{obj}}(s) + \sigma_{\text{med}}(s) c_{\text{med}}(s) \right] ds $$
其中：
- $ \sigma_{\text{obj}} $ 和 $ c_{\text{obj}} $ 分别表示物体的密度和颜色。  
- $ \sigma_{\text{med}} $ 和 $ c_{\text{med}} $ 分别表示介质的密度和颜色。  
- $ T(s) = \exp\left(-\int_{0}^{s} (\sigma_{\text{obj}}(s') + \sigma_{\text{med}}(s')) ds'\right) $ 是透射率。

为了将3DGS的离散表示与体积渲染相结合，透射率可以分解为：
$$ T_i(s) = T_{\text{obj}, i} \cdot T_{\text{med}}(s) $$
其中：
- $ T_{\text{obj}, i} = \prod_{j=1}^{i-1} (1 - \alpha_j) $ 是由前 $ i-1 $ 个高斯分布贡献的透射率。  
- $ T_{\text{med}}(s) = \exp(-\sigma_{\text{med}} s) $ 是介质的透射率。

最终，每个像素的颜色由高斯分布和介质的贡献组成：
$$ C(r) = \sum_{i=1}^{N} C_{\text{obj}, i}(r) + \sum_{i=1}^{N} C_{\text{med}, i}(r) + C_{\text{med}, \infty}(r) $$
其中：
$$ C_{\text{obj}, i}(r) = T_{\text{obj}, i} \alpha_i c_i \exp(-\sigma_{\text{attn}} s_i) $$
$$ C_{\text{med}, i}(r) = T_{\text{obj}, i} c_{\text{med}} \left[ \exp(-\sigma_{\text{bs}} s_{i-1}) - \exp(-\sigma_{\text{bs}} s_i) \right] $$
$$ C_{\text{med}, \infty}(r) = T_{\text{obj}, N} c_{\text{med}} \exp(-\sigma_{\text{bs}} s_N) $$

**3.2.2 介质属性的估计**

为了精确估计介质属性，作者使用了两个参数集：
- $ \sigma_{\text{attn}} $：用于表示物体的衰减。  
- $ \sigma_{\text{bs}} $：用于表示介质的后向散射。

这些参数通过神经网络（MLP）进行编码，网络输入包括光线方向和深度信息，输出为介质的颜色和密度。

### 3.3. 损失函数对齐（Loss Function Alignment）

为了使3DGS更好地适应高动态范围（HDR）和低光照场景，作者设计了一种新的损失函数 $ L_{\text{Reg}} $。该损失函数结合了加权L1损失和结构相似性损失（DSSIM），以提升对暗部区域的细节处理能力。

**加权L1损失：**
$$ L_{\text{Reg}-L1} = \left| W \odot (\hat{y} - y) \right| $$
其中，权重 $ W = \{w_{i,j}\} $，且 $ w_{i,j} = (\text{sg}(\hat{y}_{i,j}) + \epsilon)^{-1} $，$\text{sg}(\cdot)$ 表示停止梯度传播。

**加权DSSIM损失：**
$$ L_{\text{Reg}-DSSIM} = L_{\text{DSSIM}}(W \odot y, W \odot \hat{y}) $$

最终的损失函数为：
$$ L_{\text{Reg}} = (1 - \lambda) L_{\text{Reg}-L1} + \lambda L_{\text{Reg}-DSSIM} $$
其中，$ \lambda $ 是平衡参数，用于调整两种损失的权重。

---

## 方法总结

WaterSplatting通过结合3DGS和体积渲染，实现了高效的水下场景重建和实时渲染。其核心贡献包括：
1. **双表示方法**：利用3DGS表示几何结构，体积场表示散射介质，解决了传统方法无法处理半透明介质的问题。
2. **新的损失函数**：通过加权L1损失和DSSIM损失，提升了对HDR和低光照场景的适应能力。
3. **高效的渲染和训练**：在保持高质量重建的同时，实现了接近3DGS的实时渲染速度。

这种方法为水下三维重建提供了一种新的解决方案，具有重要的理论和实际应用价值。