---
layout: mypost
title: 问题导航
categories: [学习笔记]
---

# 2022年4月4日

## 1、读懂NeuS代码中的geometric_init的部分

## 2、inside_outside含义是什么？

## 3、读懂get_embedder: 是否前3个输入指的是坐标的3个分量？

## 4、torch.cat最后拼接的维度是什么？

## 5、torch.nn.Linear是什么含义，里面关于权重初始化是怎样的？WX=Y，X、Y都是列向量吗？

## 6、初始化方法是从哪里来的，有何道理？

## 7、读懂SDF NetWork

## 8、weight_norm是什么意思？

## 9、权重初始化中的hook操作是什么？

## 10、半小时学会Pytorch Hook：里面用到的matmul是什么操作？

## 11、prepend是什么意思？

## 12、动手写一个notebook验证博客中的关于module的说法。

## 13、略读weight_norm对应的论文

## 14、找一下Arxiv最近有没有transparent Reconstruction的文章

## 15、Softplus里的beta代表什么，越大效果如何？

## 16、revert是什么意思？

## 17、读懂SDFNetwork.__init__()

## 18、读懂SDFNetwork.forward()

## 19、skip_in在处理跳跃连接（残差）的时候，为是什么会有除以根号2的操作？

# 2023年4月5日

## 20、torch.autograd.grad是如何使用的？graph是如何作用的？

## 21、vector-Jacobian product是什么形式？

## 22、什么是finite-differences？

## 23、试着推导CSC321 Lecture 10: Page 5的两个导数是否正确

## 24、sneaky是什么意思？

## 25、autodidact是什么？

## 26、pedagogical是什么？

## 27、modular是什么？

## 28、recap是什么？

## 29、gymnastics是什么？

## 30、Markdown里矩阵$\cdots, \vdots, \ddots$怎么表示？

## 31、Markdown，在字符、公式上面加一个横线是什么？

## 32、Autodiff中，Jacobi矩阵如果不是每次全计算出来，是如何操作以加速的？

# 2023年4月6日

## 33、读完Pytorch: torch.autograd.grad

## 34、该代码块里的inputs、outputs、grad_outputs是针对前向传播还是方向传播而言的？

## 35、读完：A gentle introduction to torch.autograd

## 36、看Youtube: video from 3blue1brown，方向传播路径

## 37、在服务器上安装Stable Diffusion的Webui

## 38、直接执行bash <wget -qO https:...sh> 会安装到/home/zwn21，非理想目录

## 39、执行webui安装时，CLIP无法成功下载，github使之无法成功下载

## 40、如何将部署在服务器的网址在本地电脑上打开？

## 41、如何指定GPU？（在使用SD-webui的时候）

## 42、能承载多高的分辨率？（RTX2080ti）

## 43、如何在手机上处理图片？

## 44、

