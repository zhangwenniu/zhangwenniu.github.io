---
layout: mypost
title: 020 SparseNeuS, Fast Generalizable Neural Surface Reconstruction from Sparse Views
categories: [SDF, 表面重建, 稀疏]
---

- [标题](#标题)
  - [链接](#链接)
  - [作者](#作者)
- [要点](#要点)
  - [目的](#目的)
  - [思想](#思想)
  - [方法](#方法)
- [想法](#想法)
  - [优点](#优点)
  - [缺点](#缺点)
- [后续要读的文章](#后续要读的文章)

# 标题

SparseNeuS: Fast Generalizable Neural Surface Reconstruction from Sparse Views

2022, ECCV, 0 citations.

## 链接

论文链接：

- [PDF Arxiv Link](https://arxiv.org/pdf/2206.05737.pdf)
- [Project Link](https://www.xxlong.site/SparseNeuS/)
- [PDF Page From ECCV](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/2516_ECCV_2022_paper.php)
- [Paper ECCV PDF Link](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136920210.pdf); [Paper Supplementary Link](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136920210-supp.pdf)

代码实现：

- 官方GitHub版本。[SparseNeuS GitHub](https://github.com/xxlong0/SparseNeuS)

##  作者

> Xiaoxiao Long1 Cheng Lin2 Peng Wang1
>
> Taku Komura1 Wenping Wang3
>
> 1 The University of Hong Kong
>
> 2 Tencent Games
>
> 3 Texas A&M University

香港大学的学生为主力，指导老师是日本人。二作是来自腾讯游戏的人。整体的作者是中国人。

点进去Long Xiaoxiao的主页看了看，平均一年两篇左右的ECCV、ICCV、CVPR。很可以。PHD这么搞，难怪大家都说卷啊。

这个Long Xiaoxiao：

- 2020 ECCV 一作。
- 2021，CVPR 一作，ICCV一作。
- 2022，ECCV挂名的五作，ECCV挂名的五作，ECCV一作。

三年时间，六篇ECCV、ICCV。这么搞的吗？



另一个作者，Lin Cheng，点进去一看，也是不得了。

- 2017年就开始发论文。当年，IIKI 一作（不知道是什么期刊）；CHI挂名的最后一个作者，十作；SIGGRAPH TOG的三作。
- 2018年没有出文章。
- 2019年ICCV的一作。
- 2020年，有一篇没发出去，Arxiv四作；TVCG一作；ECCV一作。
- 2021年，CVPR三作；CVPR一作，还是Oral；ICCV二作。
- 2022年，Eurographics(EG)，二作；CVPR 二作；ECCV 四作；ECCV 二作。开始挂名了。

天。什么意思，怎么这样搞的。一年三篇起步。我真服了。



SparseNeuS的三作是Wang Peng，在NeuS(2021 NIPS)文章里面是一作。


# 要点

## 目的

 为了在稀疏视角的情况下（两到三张图像），重建出精致的三维模型。               

## 思想

对整体DTU数据集学习一个通用的模型，再迁移到具体的场景中，进行微调。微调的思路类似于MVSNet。

## 方法

使用图像特征提取网络，对图像进行特征提取。将空间切分成体素网格，每个体素顶点在不同视角上投影，得到对应的图像特征加权。网络不再学习空间中的颜色分布，而是通过对不同视角下的图片进行颜色加权，该权值是通过网络学习得来的。 

# 想法

1、VolSDF、NeuS如何做到表面重建的，我的想法是这样的：由于空间中的物体在表面上会散发出光，传播到摄像机的中心。如果给定这样的隐性约束，就能够让空间中的几何信息和纹理、亮度信息耦合起来，通过对亮度信息的监督，就能达到对几何信息的监督。纹理、亮度信息耦合起来的方法是：设计权值函数，物体发光权值最大的地方，就是空间中的物体表面。权值采用单峰的概率密度进行设计。这样，就将纹理信息、几何信息耦合起来，实现一方对另一方的监督。
2、2021年的两篇文章VolSDF、NeuS基本上成为了隐式表面重建、采用SDF进行约束的两个公认的baseline。NeuS在具体的评价指标上要略优于VolSDF，所以多数对NeuS进行改进。但是，VOlSDF在理论证明上面是优于NeuS的，不过由于算法中有过多的数学证明，导致后续的文章很难对VolSDF进行改进。所以，现在更多的情况下NeuS和VolSDF是二选一进行改进（更多的选用NeuS），暂时没看到有人将NeuS和VolSDF融合起来。
（1）我一直希望找到一个通用的推导过程，将任意的单峰概率密度函数，都能够借用NeuS、VolSDF的思路设计出对应的算法。
（2）希望能够将VoLSDF与NeuS的算法，在数学、算法上面融合起来。虽然这周有了1%的进展，但是路还很长。
3、这周设计出一个拼接的指数分布函数，设计上的基本想法是，VolSDF/NeuS两篇文章中的概率密度函数，只有一个参数对整体的分布进行约束，并且是对称的单峰函数。我认为，如果有更多的可以学习的参数来控制概率密度的走向，有机会让概率密度更加准确的在不同的场景中出现适应性的效果。比如说，实心物体和空心物体、镜面物体和透明物体，在概率密度的选择上应当是不同的，他们具有不同的材质、特性，对于重建的要求应该不一而同。
（1）目前，还没有想清楚更换概率密度函数之后，物理上如何进行解释。
（2）目前，新的概率密度函数仅仅推导出来均值和方差，还没有顺利的套用到NeuS和VolSDF的算法上。
（3）VolSDF、NeuS的代码还没读懂。有一些实验，已经有想法（比如，检验空间中已经学习到的物体表面，进行特定点的渲染情况，查看效果；交换纹理风格的时候，针对物体表面进行确定性的颜色场渲染；将颜色数值与空间中的点进行紧耦合的设计（不过，这种设计在不同的视角下、光照的变化条件下，可能会出现很大的差异）；在学习过程中，提取出Mesh表面，对该表面进行几何约束）。

## 优点

确实能够在较少视角下，重建出场景中的三维结构。     

## 缺点

技巧性很强，借用体素进行空间切分，但是没有从本质上对NeuS的渲染方式进行改进。


# 后续要读的文章

- [ ] [    ] 提供了几何先验的策略，以及加速优化的思想。MVSNerf.
- [ ] [    ] 经典的使用深度图进行多视角立体几何重建的方法。COLMAP. Pixelwise view selection for unstructured multi-view stereo. 1046 citations. 
- [ ] [    ] 点云生成mesh的算法。Kazhdan, M., Hoppe, H.: Screened poisson surface reconstruction. ACM Transactions on Graphics (ToG) 32(3), 1–13 (2013)
