---
layout: mypost
title: 077 Dynamic 3D Gaussian Fields for Urban Areas
categories: [论文, 自动驾驶, 3DGS]
---


# 原文

## 摘要

我们提出了一种高效的神经3D场景表示方法，用于大规模动态城市区域的新视角合成(NVS)。现有的方法由于其有限的视觉质量和非交互式的渲染速度，不适合混合现实或闭环仿真等应用。近期，基于光栅化的方法在新视角合成方面取得了高质量且速度令人印象深刻的成果。然而，这些方法仅限于小规模、同质化的数据，即它们无法处理由天气、季节和光照导致的严重外观和几何变化，也无法扩展到包含数千张图像的更大型动态区域。我们提出4DGF，这是一种可扩展到大规模动态城市区域的神经场景表示方法，能够处理异构输入数据，并显著提高渲染速度。我们使用3D高斯函数作为高效的几何框架，同时依靠神经场作为紧凑且灵活的外观模型。我们通过全局尺度的场景图整合场景动态特性，同时通过变形在局部层面建模铰接运动。这种分解方法实现了适用于现实世界应用的灵活场景组合。在实验中，我们在PSNR指标上超过现有最佳水平超过3分贝，在渲染速度上提高了200多倍。



## 1 引言

由于新视角合成在增强现实/虚拟现实和机器人技术等领域的重要性，近年来这一问题受到广泛关注。特别是，在不同天气、光照和季节条件下，获得大规模动态城市区域的交互式高质量渲染，是闭环机器人仿真和沉浸式虚拟现实体验的关键要求。为实现这一目标，配备传感器的车辆作为一个频繁的数据源，在城市规模的地图绘制和自动驾驶中变得越来越普及，创造了构建整个城市最新数字孪生的可能性。然而，建模这些场景极具挑战性，因为需要处理和组合异构数据源：不同的天气、光照、季节以及不同的动态和瞬态对象给动态城市区域的重建和渲染带来了重大挑战。

近年来，神经辐射场在实现静态[1, 2, 3]和动态场景[4, 5, 6, 7]的真实新视角合成方面显示出巨大潜力。虽然早期方法仅限于受控环境，但最近有几项工作探索了大规模动态区域[8, 9, 10]。其中，许多工作采用移除动态区域的方法，因此产生部分重建结果[9, 10, 11, 12, 13, 14]。相比之下，较少的工作对场景动态进行建模[15, 16, 17]。这些方法表现出明显的局限性，例如渲染速度，这可归因于体积渲染中光线遍历的高成本。

因此，基于光栅化的技术[18, 19, 20, 11]最近成为一个可行的替代方案。最值得注意的是，Kerbl等人[18]提出了一种基于3D高斯基元的场景表示方法，可以使用基于瓦片的光栅化器高效渲染，实现高视觉质量。虽然展示了令人印象深刻的渲染速度，但它需要数百万个具有高维球谐系数作为颜色表示的高斯基元才能获得良好的视图合成结果。由于高内存需求，这限制了其在大规模城市区域的应用。此外，由于其显式颜色表示，它无法建模在城市规模地图绘制和自动驾驶用例中常见的瞬态几何和外观变化，如季节和天气变化。最后，该方法仅限于静态场景，这使得表示城市区域中常见的动态对象（如移动车辆或行人）变得复杂。

为此，我们提出4DGF，这是一种采用混合方法来建模动态城市区域的方法。具体而言，我们使用3D高斯基元作为高效的几何框架。然而，我们不将外观存储为每个基元的属性，从而避免了超过80%的内存占用。相反，我们使用固定大小的神经场作为紧凑且灵活的替代方案。这使我们能够建模截然不同的外观和瞬态几何，这对于从异构数据重建城市区域至关重要。最后，我们使用基于图的表示来建模场景动态，将动态对象映射到规范空间进行重建。我们在这个规范空间中使用神经场建模非刚性变形，以应对城市区域中常见的铰接动态对象，如行人和骑自行车者。这种分解方法进一步实现了适合下游应用的灵活场景组合。本工作的主要贡献是：

• 我们引入4DGF，这是一种用于动态城市区域的混合神经场景表示方法，利用3D高斯函数作为高效的几何框架，并使用神经场作为紧凑且灵活的外观表示。

• 我们使用神经场将场景特定的瞬态几何和外观整合到3D高斯喷溅的渲染过程中，克服了其对静态、同质数据源的限制，同时受益于其高效渲染。

• 我们通过以下方式整合场景动态：i) 基于图的表示，将动态对象映射到规范空间，以及 ii) 在这个规范空间中建模非刚性变形。这使得能够从野外捕获中有效重建动态对象。

我们表明，4DGF能够有效重建包含超过一万张图像的大规模动态城市区域，在四个动态户外基准测试[21, 22, 17, 23]中达到最先进的结果，并且渲染速度比之前的最佳水平快200多倍。




## 5 结论

我们提出了4DGF，这是一种用于动态城市区域的神经场景表示方法。4DGF使用3D高斯函数作为高效的几何框架，以及紧凑但灵活的神经场来建模高度动态的大规模城市区域，能够处理不同拍摄中的大幅外观和几何变化。我们使用场景图来建模动态对象运动，并能在任意配置和条件下灵活组合表示。我们联合优化3D高斯函数、神经场和场景图，展示了最先进的视图合成质量和交互式渲染速度。

局限性。虽然4DGF改进了动态城市区域的新视角合成，但这个问题的挑战性质使其仍有进一步探索的空间。尽管我们对场景动态、外观和几何变化进行建模，但在现实世界的拍摄中还有其他因素会影响图像渲染。首先，野外拍摄通常会出现由物理成像过程引起的失真。因此，需要对卷帘快门、白平衡、运动和散焦模糊以及色差等现象进行建模，以避免重建产生伪影。其次，[18]中的针孔相机模型假设在我们的工作中仍然存在，因此我们的方法无法很好地建模更复杂的相机模型，如全景相机，这可能对某些拍摄设置来说并不理想。

更广泛的影响。我们预期我们的工作将通过改进底层技术对机器人仿真和混合现实等现实世界用例产生积极影响。虽然我们不期望我们的方法被恶意使用，但我们注意到，不准确的仿真，即我们系统的失效，可能会错误表示机器人系统的性能，可能影响现实世界的部署。
